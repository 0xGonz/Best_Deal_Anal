Findings
Document Upload & Storage: The repository’s document module writes uploaded PDF files to the server’s local filesystem and only stores a reference in the database (Neon). Specifically, when a file is uploaded via POST /api/documents/upload, the backend uses Multer in memory mode to capture the file and then writes it to a storage/documents/deal-{dealId}/ directory on disk
GitHub
. A unique filename (timestamp + original name) is generated to avoid conflicts. After saving the file to the storage/ folder, the code creates a new database record for the document, storing its metadata – deal ID, original filename, MIME type, size, and the file path – in the Postgres database
GitHub
. Notably, the actual file content is not saved in the database (there is no file_data or blob being stored in this flow, only the file path reference). Document Download Endpoint: The download route (GET /api/documents/:id/download) uses the saved database info to fetch the file from disk. On a download request, the backend looks up the document by ID in the DB, retrieves the stored filePath, and then attempts to read the file from the filesystem using that path
GitHub
. If the file is found, the endpoint streams the file bytes in the HTTP response with the proper PDF MIME type and disposition headers. However, if the file does not exist on disk (or the DB record is missing), the download handler returns a 404 error ("Document not found")
GitHub
. There is no built-in retry or alternate storage lookup in the current implementation – it assumes the file path is valid and the file is present. Observation of the Issue: Immediately after uploading a PDF, it appears to work because the file was just written and is still accessible on the server. The front-end likely displays the PDF by requesting that same /download endpoint (or perhaps using a cached blob in memory). At this point (right after upload in the same session), the file exists on disk, so the download succeeds. However, after a page refresh or in a new session, users consistently get a 404 error when the app tries to fetch /api/documents/:id/download. This means the backend could not locate the file by the path and thus reported it missing. In other words, the database still contains the document record (so the document list shows an entry), but the file itself is not being found when requested later.
Root Cause
The PDFs “disappear” on refresh because the uploaded files are not persistently stored, causing the file lookup to fail in subsequent sessions. In the current design, the file lives only on the application’s filesystem, and the path is stored in the DB. On Replit (the deployment environment in use), it appears that the filesystem storage is ephemeral or gets reset between sessions/run cycles. According to the project’s diagnostics, Replit’s environment may not retain files written at runtime unless special measures are taken. In fact, an analysis in the repo notes that running on Replit can “reset file storage”, meaning any files saved at runtime (e.g. in uploads/ or storage/ directories) might not persist across restarts or new runs
GitHub
. The database record persists (since Neon is external and durable), but the actual PDF file on disk is lost when the app restarts or the Replit container resets. Thus, when the front-end tries to load /api/documents/:id/download after a refresh/new session, the server tries to fs.readFile the path and the file isn’t there – leading to a 404 “Document not found” error. In short, the system is storing file metadata in the DB but not the file content, and the file’s absence on disk in a new session causes the download to fail. This is why the PDF only works immediately after upload (when the file is freshly written to the live filesystem) but not later. It’s worth noting that earlier versions/branches of this project attempted different storage approaches (there are references to an uploads/ directory, a temp folder, and even a file_data blob column in the database). The existence of multiple document storage implementations suggests past confusion. Currently, however, the “unified” document service in use relies on the local filesystem. Unless that filesystem is truly persistent, any restart of the app will orphan the DB references. No evidence of an automatic file deletion in code was found – the files are simply not there later, pointing to an environment persistence issue rather than an explicit deletion bug. Essentially, the underlying file persistence is misconfigured for the deployment environment.
Recommendations
1. Use Persistent Storage for Files: To fix this, you need to ensure that uploaded files are stored in a persistent location. There are a couple of ways to achieve this:
Store files in the Database (as blobs): Since you’re already using Neon/Postgres, one robust solution is to save the file data in the database itself, rather than (or in addition to) the filesystem. In fact, your codebase already hints at this approach – there’s a file_data column in the documents table and a helper in document-blob.service.ts to insert and retrieve file blobs
GitHub
GitHub
. You could refactor the upload flow to call saveDocumentBlob (or a similar DB insert) with the file’s Buffer, and store the PDF bytes in the DB. The download endpoint would then fetch the blob (via getDocumentBlob) and send it to the client. Storing documents as bytea blobs in Postgres ensures they persist across sessions and eliminates the dependency on the Replit container’s filesystem. This would definitively solve the “disappearing PDF” issue – as long as the DB record exists, the file content would be retrievable. The trade-off is that it will increase your DB storage usage and memory usage when serving files, but for moderate file sizes (your code already limits to ~10MB) this is usually fine.
Use a persistent filesystem or external storage: If you prefer to keep files on disk, you must configure Replit (or whatever host) to retain the storage/documents folder between runs. On Replit, that might involve writing to a special persistent directory or ensuring the files are saved to the project workspace (not a temporary filesystem). Make sure the upload path (storage/documents/...) is not being wiped on reboot. You may need to adjust Replit settings or use their persistent storage API. Another approach is to integrate a cloud storage service (like AWS S3 or similar) for file uploads – upload the PDF to S3 (or another durable file store) and save the URL/key in your DB. This offloads persistence to an external service. If an external storage seems heavy, storing in the DB as mentioned above is simpler given your current stack.
2. Fix the Download Logic (Error Handling): In the interim, improve the /api/documents/:id/download route to handle missing files more gracefully. Right now it blindly returns a 404 “Document not found” for any issue (missing DB record or missing file). You can enhance this to differentiate between no DB record (document never existed or was deleted) vs. file missing on disk. For example, check fs.existsSync (or catch the fs.readFile error) and return a specific message if the file is gone despite a DB entry. This would make it clear in logs/UI that the file wasn’t found on disk. The front-end could then show a user-friendly message like “File not available (it may have been removed from storage)” instead of just spinning or showing a generic error. In your repository’s context, an earlier suggestion was to return a distinct error or message when the file is missing
GitHub
, and possibly prompt the user to re-upload if needed. 3. Verify Database Records vs Storage: Ensure that the database filePath entries actually match where files are saved. In past iterations there were path mismatches (e.g. DB pointing to uploads/... vs file in storage/...). Double-check that when a file is uploaded, the filePath column (e.g. “storage/documents/deal-42/1234567890-filename.pdf”) indeed corresponds to the actual location. This appears to be the case in the current code
GitHub
GitHub
, but it’s good to confirm no remnants of older paths are lingering. Consistency will be critical once persistence is addressed. 4. Deployment Configuration: If you continue using Replit, research how to keep the file system state between restarts. It might be as simple as not hitting the “Run” button again (which might reset the container to last commit state) and instead keeping the server alive. Replit’s docs mention a persistent disk, but the behavior seen suggests it isn’t being used for these files. If needed, adjust your .replit or run configuration so that the storage/ directory is not transient. Alternatively, move the storage/documents under the project’s public/ directory if Replit preserves that – but typically, a robust fix is still to either use the DB or external storage. 5. Testing the Fix: After implementing persistence changes, thoroughly test the upload/download cycle:
Upload a PDF, ensure it’s accessible via /download.
Restart the application (or simulate a new session), and verify that the PDF can still be downloaded successfully (no 404).
Test a complete flow: upload, refresh the browser, maybe even restart the Repl, then try to access the file – it should persist and load.
Also test the deletion flow (if you have one) to ensure it removes both the DB record and the stored file/blob so you don’t accumulate orphaned data.
By storing the files in a non-ephemeral location (or in the database itself), the documents module will survive page reloads and server restarts. In summary, the root issue is that the file was only stored on the server’s volatile disk. The cure is to move to a truly persistent storage layer for the file data. Once you do that, the /api/documents/:id/download endpoint will consistently find the file data and serve the PDF across sessions, resolving the 404-after-refresh problem.