Quick sanity check before you dive in
Check	Command	Expected
Env vars present	`printenv	grep -E 'DATABASE_URL
DB reachable	psql $DATABASE_URL -c 'select 1'	returns 1
Migrations up	pnpm db:status	no pending

If any of these fail, fix them first – nothing else will be stable.

1 • Login & Session Stability
1.1 Root‑cause review
Past problem: dynamic swap between PgSession ↔ MemoryStore wiped sessions.

Desired: choose one session store at boot – PgSession in dev & prod.

1.2 Fix / confirm
Config flag

bash
Copy
Edit
USE_MEMORY_SESSIONS=false   # in .env
Boot log must show

rust
Copy
Edit
▶  Using PgSession for sessions
Health endpoint (/api/system/health)
Should return "storage":"pg", "databaseConnected":true.

Smoke test

bash
Copy
Edit
# new shell (keeps cookies)
npx supertest ./dist/index.js \
  --agent \
  --post /api/auth/login '{"username":"admin","password":"password123"}' \
  --get  /api/auth/me
# both responses must be 200
Edge cases (write integration tests)

wrong password → 401

expired cookie → 401

server restart → /me still 200

1.3 “Big red flag” alerts
Symptom	Immediate action
/api/auth/me flips 200→401	session store switched – investigate boot file path
“Database Disconnected” modal	health endpoint reports "storage":"memory" – Pg maybe down or env flag wrong

2 • Health & “Database Disconnected” banner
2.1 Goals
Banner should appear only when DB is actually unreachable.

No more “hybrid” state.

2.2 Implementation
ts
Copy
Edit
// server/health.ts
router.get("/system/health", async (req, res) => {
  try {
    await pool.query("select 1");
    return res.json({
      status: "ok",
      databaseConnected: true,
      storage: "pg",
      timestamp: new Date().toISOString(),
    });
  } catch {
    return res.status(503).json({
      status: "error",
      databaseConnected: false,
    });
  }
});
Front‑end shows banner iff databaseConnected===false.

3 • Critical Route Errors (500s)
Your trace shows /api/closing-schedules blowing up.

3.1 Reproduce
bash
Copy
Edit
curl -I http://localhost:3000/api/closing-schedules
3.2 Fix pattern
Add a guard in the Drizzle query or map step

ts
Copy
Edit
dueDate: row.dueDate ?? null
Wrap the whole route with a central asyncHandler so uncaught errors are logged but return a clean {error} envelope.

3.3 Add to test suite
ts
Copy
Edit
it("closing schedules endpoint responds 200", () =>
  request(app).set(authCookie).get("/api/closing-schedules").expect(200));
4 • Sector‑distribution charts
These rely on view_sector_rollup. Common failure modes:

Problem	Fix
View missing	pnpm db:migrate didn’t run – ensure migration created the view.
Empty chart	deals not linked in deal_sectors; add seed data.
Stale data	schedule REFRESH MATERIALIZED VIEW nightly or on write trigger.

Add a fallback UI: if query returns 0 rows, show “No sector data yet – add sectors in Deal > Overview”.

5 • Other “big problems” queue
Priority	Area	Symptom	Debug tip
1	Sessions	sporadic 401 on any page	confirm single store, secure/lax cookie
2	Pipeline Kanban	drag‑drop fails on first column	check /api/deals/:id PATCH body shape
3	Capital Calls	PDF generation 500	run locally: node scripts/genLetter.js --id 123
4	Email ingest	forwarded emails not reaching Inbox	confirm SendGrid webhook → /api/email/forward 2xx
5	Dashboard widgets	IRR widget “loading forever”	network tab – /api/funds/metrics returning 204?

Work down that list – fix, commit, push; CI should run lint + test each time.

6 • Hardening & Monitoring Checklist
Add Pino + Loki dashboards for error.level >= 40.

Prometheus alerts: DB down > 1 min, 5xx rate > 1 % over 5 min.

Playwright smoke on / and /calendar after each deploy.

Seed script (pnpm db:seed) creates admin/password123, four demo deals with sectors, one fund, one capital call – so QA always has a working dataset.

Next steps
Lock the session store in code and env – confirm it never flips again.

Knock out /closing-schedules 500 and other critical endpoints.

Add integration tests covering login, /me, and each major page route so regressions surface in CI before you ever push to prod.

Ping me as soon as you run into the next blocker or want a code diff / PR review – we’ll knock them down one by one.






